# Jinja2 template to validate Llama model in Friendli format.

type: group
decoder:
  type: group
  h_._*:
    type: repeat_group
    range:
      lo: 0
      hi: {{ num_decoder_layers - 1 | int }}
    attn:
      type: group
      c_attn:
        type: group
        lora:
          type: group
          query_A:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ hidden_size | int }}
                - {{ lora_rank_dim | int }}
          query_B:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ lora_rank_dim | int }}
                - {{ num_heads * head_size | int }}
          key_A:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ hidden_size | int }}
                - {{ lora_rank_dim | int }}
          key_B:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ lora_rank_dim | int }}
                - {{ num_kv_heads * head_size | int }}
      c_proj:
        type: group
        lora:
          type: group
          lora_A:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ num_heads * head_size | int }}
                - {{ lora_rank_dim | int }}
          lora_B:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ lora_rank_dim | int }}
                - {{ hidden_size | int }}
    mlp:
      type: group
      c_fc:
        type: group
        lora:
          type: group
          lora_A:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ hidden_size | int }}
                - {{ lora_rank_dim | int }}
          lora_B:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ lora_rank_dim | int }}
                - {{ ff_intermediate_size | int }}
      c_proj:
        type: group
        lora:
          type: group
          lora_A:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ ff_intermediate_size | int }}
                - {{ lora_rank_dim | int }}
          lora_B:
            type: group
            weight:0:
              type: data
              dtype: {{ dtype }}
              shape:
                - {{ lora_rank_dim | int }}
                - {{ hidden_size | int }}
