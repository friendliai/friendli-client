---
sidebar_position: 1
---

# ü§ó Welcome to PeriFlow

PeriFlow is the fastest engine for serving generative AI models such as GPT-3.
With PeriFlow, a company can significantly reduce the cost and environmental impact of running its generative AI models.
Users can use PeriFlow in a container and run it on the infrastructure they manage.
They can also use our PeriFlow cloud service to reduce overheads of running generative AI models themselves.

As these models enable smarter, more productive services, many companies are competitively investing to build sophisticated generative AI models, with parameter sizes ranging from a few billion to even a few trillion.
OpenAI, for example, is well-known for its large language models such as ChatGPT and GPT-4.
There are many others as well‚ÄîLLaMA, OPT, BLOOM, Gopher, PaLM, BlenderBot3, Codex, and CodeGen, to name a few.
Many companies are increasingly making their generative AI models or adapting existing models to their needs.

Utilizing such large generative AI models, however, is no simple task.
Even after users complete training models, they still face big challenges while handling the inference.
Namely, the serving costs are likely high since they require GPUs‚Äîand as traffic increases, the costs steeply increase.
Furthermore, they could pose environmental consequences.
Lastly, operating the serving infrastructure can be burdensome for users who want to solely focus on training their models.

This is where PeriFlow, an engine for generative AI, comes to the rescue.
Not only does PeriFlow provide a huge speedup of serving generative AI models, but it also provides a way for running the engine in diverse cloud or on-premise GPU resources.
Namely, the PeriFlow cloud service automatically scales depending on the traffic and handles any faults or performance problems.
Just imagine the time and cost that could be saved by leaving all tasks for utilizing a generative AI model in the hands of PeriFlow.

# ‚òÅÔ∏è PeriFlow Cloud

## Why PeriFlow Cloud?

### High performance

Users can use PeriFlow to reduce serving costs and environmental consequences significantly. They can serve much higher traffic with the same number of GPUs‚Äîor serve the same amount of traffic with notably fewer GPUs. PeriFlow can serve 10x more throughput at the same level of latency. This gain is thanks to PeriFlow‚Äôs innovative patented technology, which speeds up the execution of generative AI models.

### Diverse model and options support

PeriFlow supports various language model architectures, embedding choices, and decoding options such as greedy decoding, top-k, top-p, and beam search. PeriFlow will support diffusion models as well in the near future, so stay tuned!
Users can use PeriFlow in a container and run it by themselves, or they can use our cloud service. The cloud service supports the following features.

### Effortless deployment

PeriFlow cloud provides an easy serving experience with a Command Line Interface (CLI) and a web interface. With just a few clicks, users can deploy their models to the infrastructure that they desire. Users can move their serving between different clouds such as Azure, AWS, and GCP, and still have the same seamless experience.

### Automatic load and fault management

PeriFlow cloud monitors the resources in use and requests (responses) being sent to (sent from) the currently deployed model, allowing users a more stable model serving experience. When the number of requests sent to the deployed model increases, PeriFlow cloud automatically assigns more resources (GPU VMs) to the model, while it reduces resource usage when there are not as many requests. Furthermore, if a certain resource malfunctions, PeriFlow cloud proceeds with recovery based on the monitoring results.

## Basic Concepts

Before getting started, we recommend that you make yourself familiar with some of the following concepts.

- **Organization**: Organization refers to a root group of members collaborating to utilize the Services and may collectively cover the service fees. Typically, a company or institution acts as the primary unit of the organization. Each member within the organization has a designated [organization-level role](#organization-level-roles).
- **Project**: Project represents a sub-group within the organization that shares resources, including checkpoints, deployments, and credentials. An organization can have multiple projects, each with its own distinct purpose. Every member participating in a project is assigned a specific [project-level role](#project-level-roles).
- **Deployment**: Deployment serves your AI model via HTTP in cloud environments. You can send inference requests to deployments and get responses generated from the underlying AI model.

## Roles and Privileges

### Organization-Level Roles

Every user in the organization is either an **Owner** or a **Member**.
Each role has different privileges within the organization, described below:

| | Owner | Member |
|-|-|-|
| Collaborate with teams | ‚úì | ‚úì |
| Invite members | ‚úì | ‚úó |
| Assign roles | ‚úì | ‚úó |
| Create & delete projects | ‚úì | ‚úó |
| Manage payments | ‚úì | ‚úó |
| Delete organization | ‚úì | ‚úó |

As shown in the table above, the **Owner** can assign roles to other users within the organization.

:::info
It is possible to have multiple owners in one organization.
:::

### Project-Level Roles

There are four kinds of roles at the project level: **Admin**, **Maintainer**, **Developer**, and **Guest**.
The table below shows what each role can do inside the project:

| | Admin | Maintainer | Developer | Guest |
|-|-|-|-|-|
| Add organization members to the project | ‚úì | ‚úó | ‚úó | ‚úó |
| Assign project roles | ‚úì | ‚úó | ‚úó | ‚úó |
| Delete project | ‚úì | ‚úó | ‚úó | ‚úó |
| Delete & edit checkpoints | ‚úì | ‚úó | ‚úó | ‚úó |
| Delete & edit credentials, deployments | ‚úì | ‚úì | ‚úó | ‚úó |
| Create credentials | ‚úì | ‚úì | ‚úó | ‚úó |
| Create checkpoints, deployments | ‚úì | ‚úì | ‚úì | ‚úó |
| Read checkpoints, credentials, deployments | ‚úì | ‚úì | ‚úì | ‚úì |
| Send inference requests to deployments | ‚úì | ‚úì | ‚úì | ‚úì |

Note that **Admin** users can assign roles to project members.

:::info
If you have the **Owner** role in the organization, you have full access to all projects inside the organization.
:::
